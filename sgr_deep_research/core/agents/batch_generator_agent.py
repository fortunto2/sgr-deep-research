"""–°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–≥–µ–Ω—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ batch-–∑–∞–ø—Ä–æ—Å–æ–≤ –ø–æ —Ç–µ–º–µ."""

import logging
from typing import List, Dict, Any
from pydantic import BaseModel, Field

from sgr_deep_research.core.agents.base_agent import BaseAgent
from sgr_deep_research.services.tavily_search import TavilySearchService
from sgr_deep_research.settings import get_config

logger = logging.getLogger(__name__)


class BatchQuery(BaseModel):
    """–ú–æ–¥–µ–ª—å –æ–¥–Ω–æ–≥–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞."""

    id: int = Field(description="–ù–æ–º–µ—Ä –∑–∞–ø—Ä–æ—Å–∞ (1-N)")
    query: str = Field(description="–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∑–∞–ø—Ä–æ—Å –Ω–∞ —è–∑—ã–∫–µ —Ç–µ–º—ã")
    query_en: str = Field(description="–¢–æ—Ç –∂–µ –∑–∞–ø—Ä–æ—Å –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —è–∑—ã–∫–µ")
    aspect: str = Field(description="–ê—Å–ø–µ–∫—Ç —Ç–µ–º—ã (–∏—Å—Ç–æ—Ä–∏—è, —ç–∫–æ–Ω–æ–º–∏–∫–∞, –∫—É–ª—å—Ç—É—Ä–∞, —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –∏ —Ç.–¥.)")
    scope: str = Field(description="–ú–∞—Å—à—Ç–∞–± –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è (–æ–±–∑–æ—Ä, –¥–µ—Ç–∞–ª–∏, —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ, –∞–Ω–∞–ª–∏–∑)")
    suggested_depth: int = Field(description="–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π —É—Ä–æ–≤–µ–Ω—å –≥–ª—É–±–∏–Ω—ã (0-5)", ge=0, le=5)


class BatchPlan(BaseModel):
    """–ü–ª–∞–Ω batch-–∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è."""

    topic: str = Field(description="–ò—Å—Ö–æ–¥–Ω–∞—è —Ç–µ–º–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è")
    total_queries: int = Field(description="–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—Ä–æ—Å–æ–≤")
    languages: List[str] = Field(description="–Ø–∑—ã–∫–∏ –¥–ª—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è")
    queries: List[BatchQuery] = Field(description="–°–ø–∏—Å–æ–∫ –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤")


class BatchGeneratorAgent(BaseAgent):
    """–ê–≥–µ–Ω—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–æ —Ç–µ–º–µ."""

    def __init__(
        self,
        topic: str,
        count: int = 10,
        languages: List[str] = None,
        use_streaming: bool = False,
        with_search: bool = True,
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ batch-–∑–∞–ø—Ä–æ—Å–æ–≤.

        Args:
            topic: –û—Å–Ω–æ–≤–Ω–∞—è —Ç–µ–º–∞ –¥–ª—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
            count: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            languages: –Ø–∑—ã–∫–∏ –¥–ª—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: —Ä—É—Å—Å–∫–∏–π, –∞–Ω–≥–ª–∏–π—Å–∫–∏–π)
            use_streaming: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ –ø–æ—Ç–æ–∫–æ–≤—ã–π —Ä–µ–∂–∏–º
            with_search: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ –ø–æ–∏—Å–∫ –¥–ª—è –∞–∫—Ç—É–∞–ª–∏–∑–∞—Ü–∏–∏ –∑–∞–ø—Ä–æ—Å–æ–≤
        """
        self.topic = topic
        self.count = count
        self.languages = languages or ["ru", "en"]
        self.with_search = with_search
        self._search_service = TavilySearchService() if with_search else None

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç—É—é –∑–∞–¥–∞—á—É –¥–ª—è –±–∞–∑–æ–≤–æ–≥–æ –∫–ª–∞—Å—Å–∞
        super().__init__(
            task=f"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è {count} –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–æ —Ç–µ–º–µ: {topic}",
            toolkit=None,
            max_iterations=1,  # –ù—É–∂–µ–Ω —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω –≤—ã–∑–æ–≤ LLM
            use_streaming=use_streaming,
        )

    def _perform_research_search(self) -> str:
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–∏—Å–∫ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∞–∫—Ç—É–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ —Ç–µ–º–µ."""
        if not self.with_search or not self._search_service:
            return ""

        try:
            logger.info(f"üîç –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫ –ø–æ —Ç–µ–º–µ: {self.topic}")
            # –ü—Ä–æ—Å—Ç–æ–π –≤—ã–∑–æ–≤ –ø–æ–∏—Å–∫–∞, –∫–∞–∫ –≤ WebSearchTool
            search_results = self._search_service.search(
                query=self.topic,
                max_results=8,
            )

            if not search_results:
                return ""

            # –§–æ—Ä–º–∏—Ä—É–µ–º –∫—Ä–∞—Ç–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞
            context = "–ê–ö–¢–£–ê–õ–¨–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø –ü–û –¢–ï–ú–ï:\n\n"
            for i, source in enumerate(search_results[:5], 1):  # –¢–æ–ø-5 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                context += f"{i}. **{source.title}**\n"
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º snippet –∏–ª–∏ full_content
                content = source.snippet or source.full_content
                if content:
                    # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 200 —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è –∫—Ä–∞—Ç–∫–æ—Å—Ç–∏
                    snippet = content[:200] + "..." if len(content) > 200 else content
                    context += f"   {snippet}\n"
                context += f"   –ò—Å—Ç–æ—á–Ω–∏–∫: {source.url}\n\n"

            return context

        except Exception as e:
            logger.warning(f"–ü–æ–∏—Å–∫ –Ω–µ —É–¥–∞–ª—Å—è: {e}")
            return ""

    def _get_system_prompt(self, search_context: str = "") -> str:
        """–°–æ–∑–¥–∞–µ—Ç —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∑–∞–ø—Ä–æ—Å–æ–≤."""
        base_prompt = f"""–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—é –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π. –¢–≤–æ—è –∑–∞–¥–∞—á–∞: —Å–æ–∑–¥–∞—Ç—å {self.count} –ø—Ä–æ—Å—Ç—ã—Ö –∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–æ —Ç–µ–º–µ "{self.topic}".

{search_context}

–í–ê–ñ–ù–û: –°–û–ó–î–ê–í–ê–ô –ü–†–û–°–¢–´–ï –ò –ü–†–Ø–ú–´–ï –í–û–ü–†–û–°–´:
1. –ö–∞–∂–¥—ã–π –∑–∞–ø—Ä–æ—Å –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ö–û–†–û–¢–ö–ò–ú (–º–∞–∫—Å–∏–º—É–º 1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)
2. –ò—Å–ø–æ–ª—å–∑—É–π –ü–†–û–°–¢–´–ï —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏, –∏–∑–±–µ–≥–∞–π —Å–ª–æ–∂–Ω—ã—Ö –∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤
3. –ö–∞–∂–¥—ã–π –∑–∞–ø—Ä–æ—Å –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ö–û–ù–ö–†–ï–¢–ù–´–ú –∏ –§–ê–ö–¢–ò–ß–ï–°–ö–ò–ú
4. –ù–ï –°–û–ó–î–ê–í–ê–ô –≤–æ–ø—Ä–æ—Å—ã, —Ç—Ä–µ–±—É—é—â–∏–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —É—Ç–æ—á–Ω–µ–Ω–∏–π
5. –ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞–π –≤–æ–ø—Ä–æ—Å—ã "–ß—Ç–æ", "–ö–æ–≥–¥–∞", "–ì–¥–µ", "–ö–∞–∫" –≤–º–µ—Å—Ç–æ —Å–ª–æ–∂–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
6. –£—Ä–æ–≤–µ–Ω—å –≥–ª—É–±–∏–Ω—ã: 0-2 (–ø—Ä–æ—Å—Ç—ã–µ –∏ —Å—Ä–µ–¥–Ω–∏–µ –≤–æ–ø—Ä–æ—Å—ã)

–Ø–ó–´–ö–ò: {', '.join(self.languages)}

–ù–ï –°–û–ó–î–ê–í–ê–ô —Å–ª–æ–∂–Ω—ã–µ –∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏–µ –≤–æ–ø—Ä–æ—Å—ã —Å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ –ø–æ–¥–≤–æ–ø—Ä–æ—Å–∞–º–∏ –∏–ª–∏ —Ç—Ä–µ–±—É—é—â–∏–µ –≥–ª—É–±–æ–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞.

–°–æ–∑–¥–∞–π –ø–ª–∞–Ω –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON —Å–æ–≥–ª–∞—Å–Ω–æ —Å—Ö–µ–º–µ BatchPlan."""

        return base_prompt

    async def generate_batch_plan(self) -> BatchPlan:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–ª–∞–Ω batch-–∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è."""
        try:
            # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∞–∫—Ç—É–∞–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            search_context = self._perform_research_search()

            # –ü–æ–ª—É—á–∞–µ–º –∫–ª–∏–µ–Ω—Ç OpenAI
            config = get_config()
            from openai import AsyncOpenAI, AsyncAzureOpenAI

            if config.azure and config.azure.api_key:
                # Azure OpenAI configuration
                client = AsyncAzureOpenAI(
                    azure_endpoint=config.azure.base_url,
                    api_key=config.azure.api_key,
                    api_version=config.azure.api_version,
                )
                model = config.azure.deployment_name
            elif config.openai and config.openai.api_key:
                client = AsyncOpenAI(api_key=config.openai.api_key, base_url=config.openai.base_url)
                model = config.openai.model
            else:
                raise ValueError("–ù–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã OpenAI –∏–ª–∏ Azure OpenAI API –∫–ª—é—á–∏")

            # –°–æ–∑–¥–∞–µ–º –∑–∞–ø—Ä–æ—Å —Å structured output –∏ –∞–∫—Ç—É–∞–ª—å–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
            completion = await client.beta.chat.completions.parse(
                model=model,
                messages=[
                    {"role": "system", "content": self._get_system_prompt(search_context)},
                    {
                        "role": "user",
                        "content": f"–°–æ–∑–¥–∞–π –ø–ª–∞–Ω –¥–ª—è {self.count} –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–æ —Ç–µ–º–µ: {self.topic}",
                    },
                ],
                response_format=BatchPlan,
                # –£–±–∏—Ä–∞–µ–º temperature –¥–ª—è GPT-5 - –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ç–æ–ª—å–∫–æ default (1)
            )

            batch_plan = completion.choices[0].message.parsed

            logger.info(f"–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –ø–ª–∞–Ω –∏–∑ {len(batch_plan.queries)} –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–æ —Ç–µ–º–µ: {self.topic}")
            return batch_plan

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ batch-–ø–ª–∞–Ω–∞: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å–∫–ª—é—á–µ–Ω–∏–µ
            raise e

    async def execute(self) -> BatchPlan:
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏—é batch-–ø–ª–∞–Ω–∞."""
        return await self.generate_batch_plan()
